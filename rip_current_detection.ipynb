{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0e157500-ca29-4c42-bd12-c07884619365","cell_type":"code","source":"# Download and Extract Datasets\nimport gdown\nimport zipfile\nimport os\n\n# Download rip current dataset from Google Drive\nprint(\"ğŸ“¥ Downloading rip_data.zip from Google Drive...\")\nrip_file_id = '1hsIdrK4KBdIstQ5xpZigI8QC_OgJZPt4'\nrip_url = f'https://drive.google.com/uc?id={rip_file_id}'\ngdown.download(rip_url, 'rip_data.zip', quiet=False)\n\n# Download beach dataset from Google Drive\nprint(\"\\nğŸ“¥ Downloading beach_data.zip from Google Drive...\")\nbeach_file_id = '1LNvXCUZQbvqrlM5aQHdf3K1BUUdMJ58Q'\nbeach_url = f'https://drive.google.com/uc?id={beach_file_id}'\ngdown.download(beach_url, 'beach_data.zip', quiet=False)\n\n# Extract rip current dataset\nprint(\"\\nğŸ“¦ Extracting rip_data.zip...\")\nrip_extract_path = '/kaggle/working/rip_dataset'\nwith zipfile.ZipFile('rip_data.zip', 'r') as zip_ref:\n    zip_ref.extractall(rip_extract_path)\nprint(\"âœ… Rip current dataset extracted\")\n\n# Extract beach dataset\nprint(\"\\nğŸ“¦ Extracting beach_data.zip...\")\nbeach_extract_path = '/kaggle/working/beach_dataset'\nwith zipfile.ZipFile('beach_data.zip', 'r') as zip_ref:\n    zip_ref.extractall(beach_extract_path)\nprint(\"âœ… Beach dataset extracted\")\n\n# Function to display folder tree (folders only)\ndef display_folder_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n    if current_depth >= max_depth:\n        return\n    \n    if not os.path.exists(path):\n        return\n        \n    items = []\n    for item in os.listdir(path):\n        item_path = os.path.join(path, item)\n        if os.path.isdir(item_path):\n            items.append(item)\n    \n    items.sort()\n    \n    for i, item in enumerate(items):\n        is_last = i == len(items) - 1\n        current_prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n        print(f\"{prefix}{current_prefix}{item}/\")\n        \n        # Recursively display subdirectories\n        next_prefix = prefix + (\"    \" if is_last else \"â”‚   \")\n        item_path = os.path.join(path, item)\n        display_folder_tree(item_path, next_prefix, max_depth, current_depth + 1)\n\n# Display folder structure for both datasets\nprint(\"\\nğŸŒŠ RIP CURRENT DATASET STRUCTURE:\")\nprint(\"rip_dataset/\")\ndisplay_folder_tree(rip_extract_path)\n\nprint(\"\\nğŸ–ï¸ BEACH DATASET STRUCTURE:\")\nprint(\"beach_dataset/\")\ndisplay_folder_tree(beach_extract_path)\n\nprint(\"\\nğŸ“Š SUMMARY:\")\nprint(f\"Rip dataset location: {rip_extract_path}\")\nprint(f\"Beach dataset location: {beach_extract_path}\")\nprint(\"\\nâœ… Both datasets ready for training!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T14:52:22.182880Z","iopub.execute_input":"2025-06-05T14:52:22.183203Z","iopub.status.idle":"2025-06-05T14:53:13.179796Z","shell.execute_reply.started":"2025-06-05T14:52:22.183177Z","shell.execute_reply":"2025-06-05T14:53:13.178659Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Downloading rip_data.zip from Google Drive...\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1hsIdrK4KBdIstQ5xpZigI8QC_OgJZPt4\nFrom (redirected): https://drive.google.com/uc?id=1hsIdrK4KBdIstQ5xpZigI8QC_OgJZPt4&confirm=t&uuid=76d9c9b7-5a3f-4494-9e0e-30b4b80cd18d\nTo: /kaggle/working/rip_data.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480M/480M [00:07<00:00, 60.4MB/s] \n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“¥ Downloading beach_data.zip from Google Drive...\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1LNvXCUZQbvqrlM5aQHdf3K1BUUdMJ58Q\nFrom (redirected): https://drive.google.com/uc?id=1LNvXCUZQbvqrlM5aQHdf3K1BUUdMJ58Q&confirm=t&uuid=f7f86f3b-7f72-44b0-82b5-74c9ee49fac3\nTo: /kaggle/working/beach_data.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374M/374M [00:09<00:00, 40.2MB/s] \n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“¦ Extracting rip_data.zip...\nâœ… Rip current dataset extracted\n\nğŸ“¦ Extracting beach_data.zip...\nâœ… Beach dataset extracted\n\nğŸŒŠ RIP CURRENT DATASET STRUCTURE:\nrip_dataset/\nâ”œâ”€â”€ __MACOSX/\nâ”‚   â”œâ”€â”€ rip-currents-1/\nâ”‚   â”‚   â”œâ”€â”€ test/\nâ”‚   â”‚   â”œâ”€â”€ train/\nâ”‚   â”‚   â””â”€â”€ valid/\nâ”‚   â”œâ”€â”€ rip-currents-2/\nâ”‚   â”‚   â”œâ”€â”€ test/\nâ”‚   â”‚   â”œâ”€â”€ train/\nâ”‚   â”‚   â””â”€â”€ valid/\nâ”‚   â””â”€â”€ rip-currents-3/\nâ”‚       â”œâ”€â”€ test/\nâ”‚       â”œâ”€â”€ train/\nâ”‚       â””â”€â”€ valid/\nâ”œâ”€â”€ rip-currents-1/\nâ”‚   â”œâ”€â”€ test/\nâ”‚   â”‚   â”œâ”€â”€ images/\nâ”‚   â”‚   â””â”€â”€ labels/\nâ”‚   â”œâ”€â”€ train/\nâ”‚   â”‚   â”œâ”€â”€ images/\nâ”‚   â”‚   â””â”€â”€ labels/\nâ”‚   â””â”€â”€ valid/\nâ”‚       â”œâ”€â”€ images/\nâ”‚       â””â”€â”€ labels/\nâ”œâ”€â”€ rip-currents-2/\nâ”‚   â”œâ”€â”€ test/\nâ”‚   â”‚   â”œâ”€â”€ images/\nâ”‚   â”‚   â””â”€â”€ labels/\nâ”‚   â”œâ”€â”€ train/\nâ”‚   â”‚   â”œâ”€â”€ images/\nâ”‚   â”‚   â””â”€â”€ labels/\nâ”‚   â””â”€â”€ valid/\nâ”‚       â”œâ”€â”€ images/\nâ”‚       â””â”€â”€ labels/\nâ””â”€â”€ rip-currents-3/\n    â”œâ”€â”€ test/\n    â”‚   â”œâ”€â”€ images/\n    â”‚   â””â”€â”€ labels/\n    â”œâ”€â”€ train/\n    â”‚   â”œâ”€â”€ images/\n    â”‚   â””â”€â”€ labels/\n    â””â”€â”€ valid/\n        â”œâ”€â”€ images/\n        â””â”€â”€ labels/\n\nğŸ–ï¸ BEACH DATASET STRUCTURE:\nbeach_dataset/\nâ”œâ”€â”€ __MACOSX/\nâ”‚   â””â”€â”€ beach_data/\nâ”‚       â”œâ”€â”€ beach_pred/\nâ”‚       â”œâ”€â”€ beach_test/\nâ”‚       â””â”€â”€ beach_train/\nâ””â”€â”€ beach_data/\n    â”œâ”€â”€ beach_pred/\n    â”œâ”€â”€ beach_test/\n    â”‚   â”œâ”€â”€ beach/\n    â”‚   â””â”€â”€ not beach/\n    â””â”€â”€ beach_train/\n        â”œâ”€â”€ beach/\n        â””â”€â”€ not beach/\n\nğŸ“Š SUMMARY:\nRip dataset location: /kaggle/working/rip_dataset\nBeach dataset location: /kaggle/working/beach_dataset\n\nâœ… Both datasets ready for training!\n","output_type":"stream"}],"execution_count":2},{"id":"aae8c7ed-7118-41b5-9a32-806d8b4269db","cell_type":"code","source":"# Add this as a new cell after your current one\n\nimport shutil\nfrom collections import defaultdict\n\n# Analyze both datasets first\nprint(\"ğŸ“Š DATASET ANALYSIS\")\n\n# 1. Analyze rip current datasets\nprint(\"\\nğŸŒŠ RIP CURRENT DATASET STATS:\")\nrip_stats = defaultdict(lambda: defaultdict(int))\n\nfor dataset_num in [1, 2, 3]:\n    dataset_path = f'/kaggle/working/rip_dataset/rip-currents-{dataset_num}'\n    print(f\"\\nğŸ“ rip-currents-{dataset_num}:\")\n    \n    for split in ['train', 'test', 'valid']:\n        images_path = f'{dataset_path}/{split}/images'\n        labels_path = f'{dataset_path}/{split}/labels'\n        \n        if os.path.exists(images_path):\n            img_count = len([f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n            label_count = len([f for f in os.listdir(labels_path) if f.endswith('.txt')]) if os.path.exists(labels_path) else 0\n            \n            rip_stats[f'rip-currents-{dataset_num}'][split] = img_count\n            print(f\"  {split:>5}: {img_count:>4} images, {label_count:>4} labels\")\n\n# 2. Analyze beach classification dataset\nprint(\"\\nğŸ–ï¸ BEACH CLASSIFICATION DATASET STATS:\")\nbeach_train_path = '/kaggle/working/beach_dataset/beach_data/beach_train'\nbeach_test_path = '/kaggle/working/beach_dataset/beach_data/beach_test'\n\nfor split_name, split_path in [('train', beach_train_path), ('test', beach_test_path)]:\n    print(f\"\\nğŸ“ beach_{split_name}:\")\n    \n    for category in ['beach', 'not beach']:\n        cat_path = os.path.join(split_path, category)\n        if os.path.exists(cat_path):\n            count = len([f for f in os.listdir(cat_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n            print(f\"  {category:>10}: {count:>4} images\")\n\nprint(\"\\nğŸ¯ RECOMMENDED APPROACH:\")\nprint(\"âœ… Option 1: Two-Stage Pipeline with Separate Models\")\nprint(\"   Stage 1: Beach Classification (YOLOv8 Classification)\")\nprint(\"   Stage 2: Rip Detection (YOLOv8 Object Detection)\")\nprint(\"\\nğŸ“‹ IMPLEMENTATION STEPS:\")\nprint(\"1. Train beach classifier on beach_data\")\nprint(\"2. Combine all 3 rip datasets for better rip detection\")\nprint(\"3. Train rip detector on combined dataset\")\nprint(\"4. Create inference pipeline\")\n\n# Create combined rip dataset for better training\nprint(\"\\nğŸ”„ CREATING COMBINED RIP DATASET...\")\ncombined_rip_path = '/kaggle/working/combined_rip_dataset'\n\n# Create directory structure\nfor split in ['train', 'test', 'valid']:\n    os.makedirs(f'{combined_rip_path}/{split}/images', exist_ok=True)\n    os.makedirs(f'{combined_rip_path}/{split}/labels', exist_ok=True)\n\nprint(\"âœ… Combined rip dataset structure created\")\nprint(f\"ğŸ“ Location: {combined_rip_path}\")\n\nprint(\"\\nğŸš€ NEXT STEPS:\")\nprint(\"1. Combine all rip datasets into one\")\nprint(\"2. Prepare beach classification dataset\")\nprint(\"3. Train both models\")\nprint(\"4. Implement two-stage inference\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:05:58.847474Z","iopub.execute_input":"2025-06-05T15:05:58.849094Z","iopub.status.idle":"2025-06-05T15:05:58.901293Z","shell.execute_reply.started":"2025-06-05T15:05:58.849017Z","shell.execute_reply":"2025-06-05T15:05:58.900376Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š DATASET ANALYSIS\n\nğŸŒŠ RIP CURRENT DATASET STATS:\n\nğŸ“ rip-currents-1:\n  train: 3612 images, 3612 labels\n   test:  173 images,  173 labels\n  valid:  340 images,  340 labels\n\nğŸ“ rip-currents-2:\n  train: 1299 images, 1299 labels\n   test:  185 images,  185 labels\n  valid:  359 images,  359 labels\n\nğŸ“ rip-currents-3:\n  train: 3612 images, 3612 labels\n   test:  173 images,  173 labels\n  valid:  340 images,  340 labels\n\nğŸ–ï¸ BEACH CLASSIFICATION DATASET STATS:\n\nğŸ“ beach_train:\n       beach: 2274 images\n   not beach: 11760 images\n\nğŸ“ beach_test:\n       beach:  510 images\n   not beach: 2490 images\n\nğŸ¯ RECOMMENDED APPROACH:\nâœ… Option 1: Two-Stage Pipeline with Separate Models\n   Stage 1: Beach Classification (YOLOv8 Classification)\n   Stage 2: Rip Detection (YOLOv8 Object Detection)\n\nğŸ“‹ IMPLEMENTATION STEPS:\n1. Train beach classifier on beach_data\n2. Combine all 3 rip datasets for better rip detection\n3. Train rip detector on combined dataset\n4. Create inference pipeline\n\nğŸ”„ CREATING COMBINED RIP DATASET...\nâœ… Combined rip dataset structure created\nğŸ“ Location: /kaggle/working/combined_rip_dataset\n\nğŸš€ NEXT STEPS:\n1. Combine all rip datasets into one\n2. Prepare beach classification dataset\n3. Train both models\n4. Implement two-stage inference\n","output_type":"stream"}],"execution_count":3},{"id":"45d4fdd8-727f-4ab0-8e11-6346b9431027","cell_type":"code","source":"# Dataset Analysis and Preparation\nimport shutil\nimport yaml\nfrom collections import defaultdict\n\nprint(\"ğŸ“Š DATASET ANALYSIS AND PREPARATION\")\nprint(\"=\" * 50)\n\n# 1. Analyze rip current datasets\nprint(\"\\nğŸŒŠ RIP CURRENT DATASET STATS:\")\nrip_stats = defaultdict(lambda: defaultdict(int))\ntotal_rip_images = 0\n\nfor dataset_num in [1, 2, 3]:\n    dataset_path = f'/kaggle/working/rip_dataset/rip-currents-{dataset_num}'\n    print(f\"\\nğŸ“ rip-currents-{dataset_num}:\")\n    \n    # Check data.yaml file\n    yaml_path = f'{dataset_path}/data.yaml'\n    if os.path.exists(yaml_path):\n        with open(yaml_path, 'r') as f:\n            yaml_content = yaml.safe_load(f)\n            classes = yaml_content.get('names', ['Unknown'])\n            print(f\"  Classes: {classes}\")\n    \n    dataset_total = 0\n    for split in ['train', 'test', 'valid']:\n        images_path = f'{dataset_path}/{split}/images'\n        labels_path = f'{dataset_path}/{split}/labels'\n        \n        if os.path.exists(images_path):\n            img_count = len([f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n            label_count = len([f for f in os.listdir(labels_path) if f.endswith('.txt')]) if os.path.exists(labels_path) else 0\n            \n            rip_stats[f'rip-currents-{dataset_num}'][split] = img_count\n            dataset_total += img_count\n            print(f\"  {split:>5}: {img_count:>4} images, {label_count:>4} labels\")\n    \n    total_rip_images += dataset_total\n    print(f\"  Total: {dataset_total} images\")\n\nprint(f\"\\nğŸŒŠ TOTAL RIP CURRENT IMAGES: {total_rip_images}\")\n\n# 2. Analyze beach classification dataset\nprint(\"\\nğŸ–ï¸ BEACH CLASSIFICATION DATASET STATS:\")\nbeach_train_path = '/kaggle/working/beach_dataset/beach_data/beach_train'\nbeach_test_path = '/kaggle/working/beach_dataset/beach_data/beach_test'\n\ntotal_beach_images = 0\nfor split_name, split_path in [('train', beach_train_path), ('test', beach_test_path)]:\n    print(f\"\\nğŸ“ beach_{split_name}:\")\n    split_total = 0\n    \n    for category in ['beach', 'not beach']:\n        cat_path = os.path.join(split_path, category)\n        if os.path.exists(cat_path):\n            count = len([f for f in os.listdir(cat_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n            split_total += count\n            print(f\"  {category:>10}: {count:>4} images\")\n    \n    total_beach_images += split_total\n    print(f\"  Total: {split_total} images\")\n\nprint(f\"\\nğŸ–ï¸ TOTAL BEACH CLASSIFICATION IMAGES: {total_beach_images}\")\n\n# 3. Create combined rip dataset for better training\nprint(\"\\nğŸ”„ CREATING COMBINED RIP DATASET...\")\ncombined_rip_path = '/kaggle/working/combined_rip_dataset'\n\n# Create directory structure\nfor split in ['train', 'test', 'valid']:\n    os.makedirs(f'{combined_rip_path}/{split}/images', exist_ok=True)\n    os.makedirs(f'{combined_rip_path}/{split}/labels', exist_ok=True)\n\n# Copy files from all 3 datasets\ncopy_stats = defaultdict(int)\n\nfor dataset_num in [1, 2, 3]:\n    source_path = f'/kaggle/working/rip_dataset/rip-currents-{dataset_num}'\n    \n    for split in ['train', 'test', 'valid']:\n        source_images = f'{source_path}/{split}/images'\n        source_labels = f'{source_path}/{split}/labels'\n        dest_images = f'{combined_rip_path}/{split}/images'\n        dest_labels = f'{combined_rip_path}/{split}/labels'\n        \n        if os.path.exists(source_images):\n            # Copy images\n            for img_file in os.listdir(source_images):\n                if img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n                    src = os.path.join(source_images, img_file)\n                    dst = os.path.join(dest_images, f'rip{dataset_num}_{img_file}')\n                    shutil.copy2(src, dst)\n                    copy_stats[f'{split}_images'] += 1\n            \n            # Copy labels\n            if os.path.exists(source_labels):\n                for label_file in os.listdir(source_labels):\n                    if label_file.endswith('.txt'):\n                        src = os.path.join(source_labels, label_file)\n                        dst = os.path.join(dest_labels, f'rip{dataset_num}_{label_file}')\n                        shutil.copy2(src, dst)\n                        copy_stats[f'{split}_labels'] += 1\n\n# Create data.yaml for combined dataset\ndata_yaml_content = {\n    'train': f'{combined_rip_path}/train/images',\n    'val': f'{combined_rip_path}/valid/images',\n    'test': f'{combined_rip_path}/test/images',\n    'nc': 1,\n    'names': ['rip_current']\n}\n\nwith open(f'{combined_rip_path}/data.yaml', 'w') as f:\n    yaml.dump(data_yaml_content, f)\n\nprint(\"âœ… Combined rip dataset created!\")\nprint(\"\\nğŸ“Š COMBINED DATASET STATS:\")\nfor split in ['train', 'test', 'valid']:\n    img_count = copy_stats[f'{split}_images']\n    label_count = copy_stats[f'{split}_labels']\n    print(f\"  {split:>5}: {img_count:>4} images, {label_count:>4} labels\")\n\n# 4. Prepare beach classification dataset paths\nprint(\"\\nğŸ–ï¸ BEACH CLASSIFICATION DATASET PATHS:\")\nbeach_data_path = '/kaggle/working/beach_dataset/beach_data'\nprint(f\"Train path: {beach_data_path}/beach_train\")\nprint(f\"Test path:  {beach_data_path}/beach_test\")\n\nprint(\"\\nğŸ¯ DATASETS READY FOR TRAINING!\")\nprint(\"=\" * 50)\nprint(\"âœ… Combined Rip Detection Dataset:\")\nprint(f\"   ğŸ“ Location: {combined_rip_path}\")\nprint(f\"   ğŸ“Š Total: {sum([copy_stats[f'{split}_images'] for split in ['train', 'test', 'valid']])} images\")\n\nprint(\"\\nâœ… Beach Classification Dataset:\")\nprint(f\"   ğŸ“ Location: {beach_data_path}\")\nprint(f\"   ğŸ“Š Total: {total_beach_images} images\")\n\nprint(\"\\nğŸš€ NEXT STEPS:\")\nprint(\"1. Train beach classifier (YOLOv8 classification)\")\nprint(\"2. Train rip detector (YOLOv8 object detection)\")\nprint(\"3. Create two-stage inference pipeline\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:09:13.600610Z","iopub.execute_input":"2025-06-05T15:09:13.601002Z","iopub.status.idle":"2025-06-05T15:09:17.835461Z","shell.execute_reply.started":"2025-06-05T15:09:13.600967Z","shell.execute_reply":"2025-06-05T15:09:17.834462Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š DATASET ANALYSIS AND PREPARATION\n==================================================\n\nğŸŒŠ RIP CURRENT DATASET STATS:\n\nğŸ“ rip-currents-1:\n  Classes: {0: 'rip'}\n  train: 3612 images, 3612 labels\n   test:  173 images,  173 labels\n  valid:  340 images,  340 labels\n  Total: 4125 images\n\nğŸ“ rip-currents-2:\n  Classes: {0: 'rip'}\n  train: 1299 images, 1299 labels\n   test:  185 images,  185 labels\n  valid:  359 images,  359 labels\n  Total: 1843 images\n\nğŸ“ rip-currents-3:\n  Classes: {0: 'rip'}\n  train: 3612 images, 3612 labels\n   test:  173 images,  173 labels\n  valid:  340 images,  340 labels\n  Total: 4125 images\n\nğŸŒŠ TOTAL RIP CURRENT IMAGES: 10093\n\nğŸ–ï¸ BEACH CLASSIFICATION DATASET STATS:\n\nğŸ“ beach_train:\n       beach: 2274 images\n   not beach: 11760 images\n  Total: 14034 images\n\nğŸ“ beach_test:\n       beach:  510 images\n   not beach: 2490 images\n  Total: 3000 images\n\nğŸ–ï¸ TOTAL BEACH CLASSIFICATION IMAGES: 17034\n\nğŸ”„ CREATING COMBINED RIP DATASET...\nâœ… Combined rip dataset created!\n\nğŸ“Š COMBINED DATASET STATS:\n  train: 8523 images, 8523 labels\n   test:  531 images,  531 labels\n  valid: 1039 images, 1039 labels\n\nğŸ–ï¸ BEACH CLASSIFICATION DATASET PATHS:\nTrain path: /kaggle/working/beach_dataset/beach_data/beach_train\nTest path:  /kaggle/working/beach_dataset/beach_data/beach_test\n\nğŸ¯ DATASETS READY FOR TRAINING!\n==================================================\nâœ… Combined Rip Detection Dataset:\n   ğŸ“ Location: /kaggle/working/combined_rip_dataset\n   ğŸ“Š Total: 10093 images\n\nâœ… Beach Classification Dataset:\n   ğŸ“ Location: /kaggle/working/beach_dataset/beach_data\n   ğŸ“Š Total: 17034 images\n\nğŸš€ NEXT STEPS:\n1. Train beach classifier (YOLOv8 classification)\n2. Train rip detector (YOLOv8 object detection)\n3. Create two-stage inference pipeline\n","output_type":"stream"}],"execution_count":4},{"id":"20a8eb8e-3e42-4611-a7a0-17f2e26d7d85","cell_type":"code","source":"# Stage 1: Train Beach Classifier (YOLOv8 Classification)\nprint(\"ğŸ–ï¸ STAGE 1: TRAINING BEACH CLASSIFIER\")\nprint(\"=\" * 50)\n\n# Install and import required libraries\nimport subprocess\nimport sys\n\ndef install_package(package):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n        print(f\"âœ… {package} installed successfully\")\n    except subprocess.CalledProcessError:\n        print(f\"âŒ Failed to install {package}\")\n\nprint(\"ğŸ“¦ Installing ultralytics...\")\ninstall_package(\"ultralytics\")\n\nfrom ultralytics import YOLO\nimport torch\nimport matplotlib.pyplot as plt\nimport time\n\nprint(f\"\\nğŸ“Š SYSTEM INFO:\")\nprint(f\"âœ… PyTorch version: {torch.__version__}\")\nprint(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"âœ… CUDA device: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"âš ï¸ Using CPU for training\")\n\n# Prepare beach classification dataset\nbeach_data_path = '/kaggle/working/beach_dataset/beach_data'\nbeach_train_path = f'{beach_data_path}/beach_train'\nbeach_test_path = f'{beach_data_path}/beach_test'\n\nprint(f\"\\nğŸ“ BEACH DATASET PATHS:\")\nprint(f\"Training data: {beach_train_path}\")\nprint(f\"Testing data: {beach_test_path}\")\n\n# Verify dataset structure\nprint(f\"\\nğŸ” VERIFYING DATASET STRUCTURE:\")\nfor split_name, split_path in [('train', beach_train_path), ('test', beach_test_path)]:\n    print(f\"ğŸ“ {split_name}:\")\n    for category in ['beach', 'not beach']:\n        cat_path = os.path.join(split_path, category)\n        if os.path.exists(cat_path):\n            count = len([f for f in os.listdir(cat_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n            print(f\"  {category:>10}: {count:>4} images\")\n        else:\n            print(f\"  {category:>10}: âŒ Missing\")\n\n# Initialize YOLOv8 classification model\nprint(f\"\\nğŸ¤– INITIALIZING YOLO CLASSIFICATION MODEL...\")\nbeach_model = YOLO('yolov8n-cls.pt')  # Load pretrained classification model\nprint(\"âœ… YOLOv8n-cls model loaded\")\n\n# Training parameters\nEPOCHS = 50\nBATCH_SIZE = 16\nIMAGE_SIZE = 224  # Standard for classification\nPATIENCE = 10\n\nprint(f\"\\nâš™ï¸ TRAINING PARAMETERS:\")\nprint(f\"   Epochs: {EPOCHS}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   Image size: {IMAGE_SIZE}\")\nprint(f\"   Patience: {PATIENCE}\")\nprint(f\"   Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n\n# Start training\nprint(f\"\\nğŸš€ STARTING BEACH CLASSIFICATION TRAINING...\")\nprint(\"=\" * 50)\n\nstart_time = time.time()\n\ntry:\n    # Train the model\n    results = beach_model.train(\n        data=beach_train_path,\n        epochs=EPOCHS,\n        imgsz=IMAGE_SIZE,\n        batch=BATCH_SIZE,\n        patience=PATIENCE,\n        save=True,\n        plots=True,\n        val=True,\n        project='/kaggle/working/beach_classifier_runs',\n        name='beach_classification_v1'\n    )\n    \n    training_time = time.time() - start_time\n    print(f\"\\nâœ… TRAINING COMPLETED!\")\n    print(f\"â±ï¸ Training time: {training_time/60:.1f} minutes\")\n    \n    # Save the best model\n    best_model_path = '/kaggle/working/beach_classifier_best.pt'\n    beach_model.export(format='torchscript', name=best_model_path.replace('.pt', '.torchscript'))\n    print(f\"ğŸ’¾ Best model saved to: {best_model_path}\")\n    \n    # Display training results\n    print(f\"\\nğŸ“Š TRAINING RESULTS:\")\n    if hasattr(results, 'results_dict'):\n        for key, value in results.results_dict.items():\n            if 'accuracy' in key.lower() or 'loss' in key.lower():\n                print(f\"   {key}: {value:.4f}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Training failed: {str(e)}\")\n    print(\"ğŸ’¡ This might be due to dataset format issues\")\n\n# Test the trained model\nprint(f\"\\nğŸ§ª TESTING BEACH CLASSIFIER...\")\ntry:\n    # Load the trained model\n    trained_model = YOLO('/kaggle/working/beach_classifier_runs/beach_classification_v1/weights/best.pt')\n    \n    # Test on validation set\n    val_results = trained_model.val(data=beach_test_path)\n    print(\"âœ… Validation completed\")\n    \n    print(f\"\\nğŸ¯ BEACH CLASSIFIER READY!\")\n    print(f\"ğŸ“ Model location: /kaggle/working/beach_classifier_runs/beach_classification_v1/weights/best.pt\")\n    print(f\"ğŸš€ Ready for Stage 2: Rip Current Detection Training\")\n    \nexcept Exception as e:\n    print(f\"âš ï¸ Testing failed: {str(e)}\")\n    print(\"ğŸ’¡ Model training may have completed but testing encountered issues\")\n\nprint(f\"\\n\" + \"=\" * 50)\nprint(f\"ğŸ–ï¸ STAGE 1 COMPLETED - BEACH CLASSIFIER TRAINED\")\nprint(f\"ğŸŒŠ NEXT: Stage 2 - Train Rip Current Detector\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0852cbe2-dba5-49f0-b9d0-22aa90726228","cell_type":"code","source":"# Stage 2: Train Rip Current Detector (YOLOv8 Object Detection)\nprint(\"ğŸŒŠ STAGE 2: TRAINING RIP CURRENT DETECTOR\")\nprint(\"=\" * 50)\n\n# Install and import required libraries\nimport subprocess\nimport sys\n\ndef install_package(package):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n        print(f\"âœ… {package} installed successfully\")\n    except subprocess.CalledProcessError:\n        print(f\"âŒ Failed to install {package}\")\n\nprint(\"ğŸ“¦ Installing ultralytics...\")\ninstall_package(\"ultralytics\")\n\nfrom ultralytics import YOLO\nimport torch\nimport matplotlib.pyplot as plt\nimport yaml\nimport time\nimport shutil\nfrom collections import defaultdict\n\nprint(f\"\\nğŸ“Š SYSTEM INFO:\")\nprint(f\"âœ… PyTorch version: {torch.__version__}\")\nprint(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"âœ… CUDA device: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"âš ï¸ Using CPU for training\")\n\n# First, combine all rip current datasets\nprint(f\"\\nğŸ”„ PREPARING COMBINED RIP DATASET...\")\ncombined_rip_path = '/kaggle/working/combined_rip_dataset'\n\n# Create directory structure\nfor split in ['train', 'test', 'valid']:\n    os.makedirs(f'{combined_rip_path}/{split}/images', exist_ok=True)\n    os.makedirs(f'{combined_rip_path}/{split}/labels', exist_ok=True)\n\n# Copy files from all 3 rip datasets\ncopy_stats = defaultdict(int)\n\nfor dataset_num in [1, 2, 3]:\n    source_path = f'/kaggle/working/rip_dataset/rip-currents-{dataset_num}'\n    \n    for split in ['train', 'test', 'valid']:\n        source_images = f'{source_path}/{split}/images'\n        source_labels = f'{source_path}/{split}/labels'\n        dest_images = f'{combined_rip_path}/{split}/images'\n        dest_labels = f'{combined_rip_path}/{split}/labels'\n        \n        if os.path.exists(source_images):\n            # Copy images\n            for img_file in os.listdir(source_images):\n                if img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n                    src = os.path.join(source_images, img_file)\n                    dst = os.path.join(dest_images, f'rip{dataset_num}_{img_file}')\n                    if not os.path.exists(dst):  # Avoid duplicates\n                        shutil.copy2(src, dst)\n                        copy_stats[f'{split}_images'] += 1\n            \n            # Copy labels\n            if os.path.exists(source_labels):\n                for label_file in os.listdir(source_labels):\n                    if label_file.endswith('.txt'):\n                        src = os.path.join(source_labels, label_file)\n                        dst = os.path.join(dest_labels, f'rip{dataset_num}_{label_file}')\n                        if not os.path.exists(dst):  # Avoid duplicates\n                            shutil.copy2(src, dst)\n                            copy_stats[f'{split}_labels'] += 1\n\n# Create data.yaml for combined dataset\ndata_yaml_content = {\n    'train': f'{combined_rip_path}/train/images',\n    'val': f'{combined_rip_path}/valid/images',\n    'test': f'{combined_rip_path}/test/images',\n    'nc': 1,\n    'names': ['rip_current']\n}\n\nyaml_path = f'{combined_rip_path}/data.yaml'\nwith open(yaml_path, 'w') as f:\n    yaml.dump(data_yaml_content, f)\n\nprint(\"âœ… Combined rip dataset created!\")\nprint(\"\\nğŸ“Š COMBINED DATASET STATS:\")\nfor split in ['train', 'test', 'valid']:\n    img_count = copy_stats[f'{split}_images']\n    label_count = copy_stats[f'{split}_labels']\n    print(f\"  {split:>5}: {img_count:>4} images, {label_count:>4} labels\")\n\ntotal_images = sum([copy_stats[f'{split}_images'] for split in ['train', 'test', 'valid']])\nprint(f\"\\nğŸŒŠ TOTAL RIP IMAGES: {total_images}\")\n\n# Initialize YOLOv8 object detection model\nprint(f\"\\nğŸ¤– INITIALIZING YOLO OBJECT DETECTION MODEL...\")\nrip_model = YOLO('yolov8n.pt')  # Load pretrained object detection model\nprint(\"âœ… YOLOv8n model loaded\")\n\n# Training parameters\nEPOCHS = 100\nBATCH_SIZE = 16\nIMAGE_SIZE = 640  # Standard for object detection\nPATIENCE = 15\n\nprint(f\"\\nâš™ï¸ TRAINING PARAMETERS:\")\nprint(f\"   Epochs: {EPOCHS}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   Image size: {IMAGE_SIZE}\")\nprint(f\"   Patience: {PATIENCE}\")\nprint(f\"   Dataset: {yaml_path}\")\nprint(f\"   Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n\n# Start training\nprint(f\"\\nğŸš€ STARTING RIP CURRENT DETECTION TRAINING...\")\nprint(\"=\" * 50)\n\nstart_time = time.time()\n\ntry:\n    # Train the model\n    results = rip_model.train(\n        data=yaml_path,\n        epochs=EPOCHS,\n        imgsz=IMAGE_SIZE,\n        batch=BATCH_SIZE,\n        patience=PATIENCE,\n        save=True,\n        plots=True,\n        val=True,\n        project='/kaggle/working/rip_detector_runs',\n        name='rip_detection_v1',\n        workers=2  # Reduce workers for Kaggle\n    )\n    \n    training_time = time.time() - start_time\n    print(f\"\\nâœ… TRAINING COMPLETED!\")\n    print(f\"â±ï¸ Training time: {training_time/60:.1f} minutes\")\n    \n    # Save the best model with a simple name\n    best_model_path = '/kaggle/working/rip_detector_best.pt'\n    trained_model_path = '/kaggle/working/rip_detector_runs/rip_detection_v1/weights/best.pt'\n    \n    if os.path.exists(trained_model_path):\n        shutil.copy2(trained_model_path, best_model_path)\n        print(f\"ğŸ’¾ Best model copied to: {best_model_path}\")\n    \n    # Display training results\n    print(f\"\\nğŸ“Š TRAINING RESULTS:\")\n    print(f\"   Model saved to: {trained_model_path}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Training failed: {str(e)}\")\n    print(\"ğŸ’¡ This might be due to memory issues or dataset format\")\n    print(\"ğŸ”§ Try reducing batch_size or epochs if needed\")\n\n# Test the trained model\nprint(f\"\\nğŸ§ª TESTING RIP DETECTOR...\")\ntry:\n    # Load the trained model\n    if os.path.exists('/kaggle/working/rip_detector_runs/rip_detection_v1/weights/best.pt'):\n        trained_model = YOLO('/kaggle/working/rip_detector_runs/rip_detection_v1/weights/best.pt')\n        \n        # Validate on test set\n        val_results = trained_model.val(data=yaml_path, split='test')\n        print(\"âœ… Validation completed\")\n        \n        print(f\"\\nğŸ¯ RIP DETECTOR READY!\")\n        print(f\"ğŸ“ Model location: /kaggle/working/rip_detector_runs/rip_detection_v1/weights/best.pt\")\n        print(f\"ğŸ“ Copy location: /kaggle/working/rip_detector_best.pt\")\n        \n    else:\n        print(\"âš ï¸ Trained model not found at expected location\")\n        \nexcept Exception as e:\n    print(f\"âš ï¸ Testing failed: {str(e)}\")\n    print(\"ğŸ’¡ Model training may have completed but testing encountered issues\")\n\nprint(f\"\\n\" + \"=\" * 50)\nprint(f\"ğŸŒŠ STAGE 2 COMPLETED - RIP DETECTOR TRAINED\")\nprint(f\"ğŸ”— NEXT: Stage 3 - Create Two-Stage Pipeline\")\nprint(f\"ğŸ“‹ Available models:\")\nprint(f\"   ğŸ–ï¸ Beach Classifier: /kaggle/working/beach_classifier_runs/beach_classification_v1/weights/best.pt\")\nprint(f\"   ğŸŒŠ Rip Detector: /kaggle/working/rip_detector_runs/rip_detection_v1/weights/best.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"af99fc32-640c-4620-896c-445556c784ec","cell_type":"code","source":"# Stage 3: Create Two-Stage Inference Pipeline\nprint(\"ğŸ”— STAGE 3: CREATING TWO-STAGE INFERENCE PIPELINE\")\nprint(\"=\" * 50)\n\n# Install and import required libraries\nimport subprocess\nimport sys\n\ndef install_package(package):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n        print(f\"âœ… {package} installed successfully\")\n    except subprocess.CalledProcessError:\n        print(f\"âŒ Failed to install {package}\")\n\nprint(\"ğŸ“¦ Installing required packages...\")\ninstall_package(\"ultralytics\")\n\nfrom ultralytics import YOLO\nimport torch\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport time\n\nprint(f\"\\nğŸ“Š SYSTEM INFO:\")\nprint(f\"âœ… PyTorch version: {torch.__version__}\")\nprint(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n\n# Define model paths\nBEACH_MODEL_PATH = '/kaggle/working/beach_classifier_runs/beach_classification_v1/weights/best.pt'\nRIP_MODEL_PATH = '/kaggle/working/rip_detector_runs/rip_detection_v1/weights/best.pt'\n\n# Alternative paths if training was done differently\nALT_BEACH_PATH = '/kaggle/working/beach_classifier_best.pt'\nALT_RIP_PATH = '/kaggle/working/rip_detector_best.pt'\n\nprint(f\"\\nğŸ” CHECKING FOR TRAINED MODELS:\")\n\n# Check for beach classifier\nbeach_model_found = False\nif os.path.exists(BEACH_MODEL_PATH):\n    print(f\"âœ… Beach classifier found: {BEACH_MODEL_PATH}\")\n    beach_model_found = True\nelif os.path.exists(ALT_BEACH_PATH):\n    print(f\"âœ… Beach classifier found: {ALT_BEACH_PATH}\")\n    BEACH_MODEL_PATH = ALT_BEACH_PATH\n    beach_model_found = True\nelse:\n    print(f\"âŒ Beach classifier not found - training may be needed\")\n\n# Check for rip detector\nrip_model_found = False\nif os.path.exists(RIP_MODEL_PATH):\n    print(f\"âœ… Rip detector found: {RIP_MODEL_PATH}\")\n    rip_model_found = True\nelif os.path.exists(ALT_RIP_PATH):\n    print(f\"âœ… Rip detector found: {ALT_RIP_PATH}\")\n    RIP_MODEL_PATH = ALT_RIP_PATH\n    rip_model_found = True\nelse:\n    print(f\"âŒ Rip detector not found - training may be needed\")\n\n# If models not found, use pretrained models for demonstration\nif not beach_model_found:\n    print(f\"âš ï¸ Using pretrained YOLOv8n-cls for beach classification demo\")\n    BEACH_MODEL_PATH = 'yolov8n-cls.pt'\n\nif not rip_model_found:\n    print(f\"âš ï¸ Using pretrained YOLOv8n for rip detection demo\")\n    RIP_MODEL_PATH = 'yolov8n.pt'\n\n# Load models\nprint(f\"\\nğŸ¤– LOADING MODELS...\")\ntry:\n    beach_classifier = YOLO(BEACH_MODEL_PATH)\n    print(f\"âœ… Beach classifier loaded\")\nexcept Exception as e:\n    print(f\"âŒ Failed to load beach classifier: {e}\")\n    beach_classifier = None\n\ntry:\n    rip_detector = YOLO(RIP_MODEL_PATH)\n    print(f\"âœ… Rip detector loaded\")\nexcept Exception as e:\n    print(f\"âŒ Failed to load rip detector: {e}\")\n    rip_detector = None\n\n# Define the Two-Stage Pipeline Class\nclass RipCurrentPipeline:\n    def __init__(self, beach_classifier, rip_detector, beach_threshold=0.7, rip_threshold=0.5):\n        self.beach_classifier = beach_classifier\n        self.rip_detector = rip_detector\n        self.beach_threshold = beach_threshold\n        self.rip_threshold = rip_threshold\n    \n    def predict(self, image_path, verbose=True):\n        \"\"\"\n        Two-stage prediction pipeline\n        Stage 1: Check if image is a beach\n        Stage 2: If beach, detect rip currents\n        \"\"\"\n        results = {\n            'is_beach': False,\n            'beach_confidence': 0.0,\n            'rip_detections': [],\n            'total_rips': 0,\n            'processing_time': 0.0,\n            'message': ''\n        }\n        \n        start_time = time.time()\n        \n        try:\n            # Stage 1: Beach Classification\n            if verbose:\n                print(f\"ğŸ–ï¸ Stage 1: Checking if image is a beach...\")\n            \n            if self.beach_classifier is not None:\n                beach_results = self.beach_classifier(image_path, verbose=False)\n                \n                # For classification models, get top prediction\n                if hasattr(beach_results[0], 'probs'):\n                    beach_confidence = float(beach_results[0].probs.top1conf)\n                    top_class = int(beach_results[0].probs.top1)\n                    \n                    # Assuming class 0 = beach, class 1 = not_beach\n                    is_beach = (top_class == 0 and beach_confidence > self.beach_threshold)\n                    \n                    results['beach_confidence'] = beach_confidence\n                    results['is_beach'] = is_beach\n                    \n                    if verbose:\n                        print(f\"   Beach confidence: {beach_confidence:.3f}\")\n                        print(f\"   Is beach: {is_beach}\")\n                \n                else:\n                    # Fallback: assume it's a beach for demo\n                    results['is_beach'] = True\n                    results['beach_confidence'] = 0.8\n                    if verbose:\n                        print(f\"   âš ï¸ Using fallback beach detection\")\n            else:\n                # No beach classifier available\n                results['is_beach'] = True\n                results['beach_confidence'] = 1.0\n                if verbose:\n                    print(f\"   âš ï¸ No beach classifier - assuming beach\")\n            \n            # Stage 2: Rip Current Detection (only if beach)\n            if results['is_beach']:\n                if verbose:\n                    print(f\"ğŸŒŠ Stage 2: Detecting rip currents...\")\n                \n                if self.rip_detector is not None:\n                    rip_results = self.rip_detector(image_path, verbose=False)\n                    \n                    detections = []\n                    for result in rip_results:\n                        if hasattr(result, 'boxes') and result.boxes is not None:\n                            boxes = result.boxes\n                            for i in range(len(boxes.xyxy)):\n                                confidence = float(boxes.conf[i])\n                                if confidence > self.rip_threshold:\n                                    bbox = boxes.xyxy[i].cpu().numpy()\n                                    detections.append({\n                                        'bbox': bbox,\n                                        'confidence': confidence,\n                                        'class': 'rip_current'\n                                    })\n                    \n                    results['rip_detections'] = detections\n                    results['total_rips'] = len(detections)\n                    \n                    if verbose:\n                        print(f\"   Rip currents detected: {len(detections)}\")\n                        for i, det in enumerate(detections):\n                            print(f\"   Detection {i+1}: confidence {det['confidence']:.3f}\")\n                \n                results['message'] = f\"Beach detected! Found {results['total_rips']} rip current(s)\"\n            else:\n                results['message'] = \"Not a beach image - no rip detection performed\"\n                if verbose:\n                    print(f\"âŒ Not a beach - skipping rip detection\")\n        \n        except Exception as e:\n            results['message'] = f\"Error during processing: {str(e)}\"\n            if verbose:\n                print(f\"âŒ Error: {str(e)}\")\n        \n        results['processing_time'] = time.time() - start_time\n        return results\n    \n    def visualize_results(self, image_path, results):\n        \"\"\"Visualize the detection results\"\"\"\n        try:\n            # Load and display image\n            image = cv2.imread(image_path)\n            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            \n            plt.figure(figsize=(12, 8))\n            plt.imshow(image_rgb)\n            \n            # Draw bounding boxes for rip detections\n            if results['rip_detections']:\n                for detection in results['rip_detections']:\n                    bbox = detection['bbox']\n                    confidence = detection['confidence']\n                    \n                    # Draw rectangle\n                    rect = plt.Rectangle(\n                        (bbox[0], bbox[1]), \n                        bbox[2] - bbox[0], \n                        bbox[3] - bbox[1],\n                        linewidth=3, \n                        edgecolor='red', \n                        facecolor='none'\n                    )\n                    plt.gca().add_patch(rect)\n                    \n                    # Add confidence label\n                    plt.text(\n                        bbox[0], bbox[1] - 10, \n                        f'Rip: {confidence:.2f}', \n                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='red', alpha=0.7),\n                        fontsize=10, color='white'\n                    )\n            \n            # Add title with results\n            title = f\"Beach: {results['beach_confidence']:.2f} | Rips: {results['total_rips']} | {results['message']}\"\n            plt.title(title, fontsize=12, pad=20)\n            plt.axis('off')\n            plt.tight_layout()\n            plt.show()\n            \n        except Exception as e:\n            print(f\"âŒ Visualization error: {str(e)}\")\n\n# Initialize the pipeline\nprint(f\"\\nğŸ”— INITIALIZING TWO-STAGE PIPELINE...\")\npipeline = RipCurrentPipeline(\n    beach_classifier=beach_classifier,\n    rip_detector=rip_detector,\n    beach_threshold=0.7,\n    rip_threshold=0.5\n)\n\nprint(f\"âœ… Two-stage pipeline initialized!\")\nprint(f\"âš™ï¸ Beach threshold: 0.7\")\nprint(f\"âš™ï¸ Rip threshold: 0.5\")\n\n# Test with sample images from dataset\nprint(f\"\\nğŸ§ª TESTING PIPELINE WITH SAMPLE IMAGES:\")\nprint(\"=\" * 50)\n\n# Find some test images\ntest_images = []\nrip_test_path = '/kaggle/working/rip_dataset/rip-currents-1/test/images'\nbeach_test_path = '/kaggle/working/beach_dataset/beach_data/beach_test'\n\n# Get rip current test images\nif os.path.exists(rip_test_path):\n    rip_images = [f for f in os.listdir(rip_test_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n    if rip_images:\n        test_images.append(('Beach with rips', os.path.join(rip_test_path, rip_images[0])))\n\n# Get beach test images\nif os.path.exists(f'{beach_test_path}/beach'):\n    beach_images = [f for f in os.listdir(f'{beach_test_path}/beach') if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n    if beach_images:\n        test_images.append(('Beach', os.path.join(f'{beach_test_path}/beach', beach_images[0])))\n\n# Get non-beach test images\nif os.path.exists(f'{beach_test_path}/not beach'):\n    non_beach_images = [f for f in os.listdir(f'{beach_test_path}/not beach') if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n    if non_beach_images:\n        test_images.append(('Not beach', os.path.join(f'{beach_test_path}/not beach', non_beach_images[0])))\n\n# Test the pipeline\nfor i, (label, image_path) in enumerate(test_images[:3]):  # Test first 3 images\n    print(f\"\\nğŸ–¼ï¸ Test {i+1}: {label}\")\n    print(f\"ğŸ“ Image: {os.path.basename(image_path)}\")\n    \n    results = pipeline.predict(image_path, verbose=True)\n    \n    print(f\"ğŸ“Š Results:\")\n    print(f\"   Processing time: {results['processing_time']:.2f}s\")\n    print(f\"   Message: {results['message']}\")\n    \n    # Visualize results\n    pipeline.visualize_results(image_path, results)\n\nprint(f\"\\n\" + \"=\" * 50)\nprint(f\"ğŸ‰ TWO-STAGE PIPELINE READY!\")\nprint(f\"ğŸ”— Usage: pipeline.predict(image_path)\")\nprint(f\"ğŸ“Š Pipeline components:\")\nprint(f\"   ğŸ–ï¸ Beach Classifier: {'âœ… Loaded' if beach_classifier else 'âŒ Missing'}\")\nprint(f\"   ğŸŒŠ Rip Detector: {'âœ… Loaded' if rip_detector else 'âŒ Missing'}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}