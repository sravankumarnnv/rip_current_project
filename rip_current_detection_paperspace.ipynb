{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4730372",
   "metadata": {},
   "source": [
    "# Rip Current Detection System\n",
    "\n",
    "## Two-Stage Pipeline Approach\n",
    "\n",
    "This notebook implements a comprehensive rip current detection system using a two-stage pipeline:\n",
    "\n",
    "1. **Stage 1: Beach Classification** - Filters out non-beach images to reduce false positives\n",
    "2. **Stage 2: Rip Current Detection** - Detects rip currents in confirmed beach images\n",
    "\n",
    "### Project Structure\n",
    "\n",
    "1. **Dataset Setup and Preparation**\n",
    "   - Use mounted datasets from Paperspace\n",
    "   - Analyze dataset structure and statistics\n",
    "   - Combine multiple rip current datasets for better training\n",
    "\n",
    "2. **Model Training**\n",
    "   - Train beach classifier (YOLOv8 classification)\n",
    "   - Train rip current detector (YOLOv8 object detection)\n",
    "\n",
    "3. **Two-Stage Inference Pipeline**\n",
    "   - Implement complete pipeline with both models\n",
    "   - Test and visualize results\n",
    "\n",
    "### Expected Results\n",
    "\n",
    "- Reduced false positives by filtering non-beach images\n",
    "- Improved rip current detection accuracy\n",
    "- Complete end-to-end inference system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a113cd",
   "metadata": {},
   "source": [
    "## 1. Dataset Setup and Preparation\n",
    "\n",
    "First, we'll verify the mounted datasets and analyze their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4fdd8-727f-4ab0-8e11-6346b9431027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T15:09:13.601002Z",
     "iopub.status.busy": "2025-06-05T15:09:13.600610Z",
     "iopub.status.idle": "2025-06-05T15:09:17.835461Z",
     "shell.execute_reply": "2025-06-05T15:09:17.834462Z",
     "shell.execute_reply.started": "2025-06-05T15:09:13.600967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 DATASET ANALYSIS AND PREPARATION\n",
      "==================================================\n",
      "\n",
      "🌊 RIP CURRENT DATASET STATS:\n",
      "\n",
      "📁 rip-currents-1:\n",
      "  Classes: {0: 'rip'}\n",
      "  train: 3612 images, 3612 labels\n",
      "   test:  173 images,  173 labels\n",
      "  valid:  340 images,  340 labels\n",
      "  Total: 4125 images\n",
      "\n",
      "📁 rip-currents-2:\n",
      "  Classes: {0: 'rip'}\n",
      "  train: 1299 images, 1299 labels\n",
      "   test:  185 images,  185 labels\n",
      "  valid:  359 images,  359 labels\n",
      "  Total: 1843 images\n",
      "\n",
      "📁 rip-currents-3:\n",
      "  Classes: {0: 'rip'}\n",
      "  train: 3612 images, 3612 labels\n",
      "   test:  173 images,  173 labels\n",
      "  valid:  340 images,  340 labels\n",
      "  Total: 4125 images\n",
      "\n",
      "🌊 TOTAL RIP CURRENT IMAGES: 10093\n",
      "\n",
      "🏖️ BEACH CLASSIFICATION DATASET STATS:\n",
      "\n",
      "📁 beach_train:\n",
      "       beach: 2274 images\n",
      "   not beach: 11760 images\n",
      "  Total: 14034 images\n",
      "\n",
      "📁 beach_test:\n",
      "       beach:  510 images\n",
      "   not beach: 2490 images\n",
      "  Total: 3000 images\n",
      "\n",
      "🏖️ TOTAL BEACH CLASSIFICATION IMAGES: 17034\n",
      "\n",
      "🔄 CREATING COMBINED RIP DATASET...\n",
      "✅ Combined rip dataset created!\n",
      "\n",
      "📊 COMBINED DATASET STATS:\n",
      "  train: 8523 images, 8523 labels\n",
      "   test:  531 images,  531 labels\n",
      "  valid: 1039 images, 1039 labels\n",
      "\n",
      "🏖️ BEACH CLASSIFICATION DATASET PATHS:\n",
      "Train path: /kaggle/working/beach_dataset/beach_data/beach_train\n",
      "Test path:  /kaggle/working/beach_dataset/beach_data/beach_test\n",
      "\n",
      "🎯 DATASETS READY FOR TRAINING!\n",
      "==================================================\n",
      "✅ Combined Rip Detection Dataset:\n",
      "   📍 Location: /kaggle/working/combined_rip_dataset\n",
      "   📊 Total: 10093 images\n",
      "\n",
      "✅ Beach Classification Dataset:\n",
      "   📍 Location: /kaggle/working/beach_dataset/beach_data\n",
      "   📊 Total: 17034 images\n",
      "\n",
      "🚀 NEXT STEPS:\n",
      "1. Train beach classifier (YOLOv8 classification)\n",
      "2. Train rip detector (YOLOv8 object detection)\n",
      "3. Create two-stage inference pipeline\n"
     ]
    }
   ],
   "source": [
    "# Dataset Setup and Analysis for Paperspace\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"📍 PAPERSPACE DATASET SETUP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define dataset paths for Paperspace\n",
    "beach_dataset_path = '/datasets/beach'\n",
    "rip_dataset_path = '/datasets/rip'\n",
    "\n",
    "# Working directory for outputs\n",
    "working_dir = '/storage'  # Paperspace persistent storage\n",
    "os.makedirs(working_dir, exist_ok=True)\n",
    "\n",
    "print(f\"🏖️ Beach dataset path: {beach_dataset_path}\")\n",
    "print(f\"🌊 Rip dataset path: {rip_dataset_path}\")\n",
    "print(f\"💾 Working directory: {working_dir}\")\n",
    "\n",
    "# Verify datasets exist\n",
    "print(f\"\\n🔍 VERIFYING MOUNTED DATASETS:\")\n",
    "if os.path.exists(beach_dataset_path):\n",
    "    print(f\"✅ Beach dataset found: {beach_dataset_path}\")\n",
    "else:\n",
    "    print(f\"❌ Beach dataset not found: {beach_dataset_path}\")\n",
    "\n",
    "if os.path.exists(rip_dataset_path):\n",
    "    print(f\"✅ Rip dataset found: {rip_dataset_path}\")\n",
    "else:\n",
    "    print(f\"❌ Rip dataset not found: {rip_dataset_path}\")\n",
    "\n",
    "# Function to display folder tree\n",
    "def display_folder_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    if current_depth >= max_depth or not os.path.exists(path):\n",
    "        return\n",
    "        \n",
    "    items = [item for item in os.listdir(path) if os.path.isdir(os.path.join(path, item))]\n",
    "    items.sort()\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"└── \" if is_last else \"├── \"\n",
    "        print(f\"{prefix}{current_prefix}{item}/\")\n",
    "        \n",
    "        next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "        item_path = os.path.join(path, item)\n",
    "        display_folder_tree(item_path, next_prefix, max_depth, current_depth + 1)\n",
    "\n",
    "# Display folder structures\n",
    "print(\"\\n📁 DATASET STRUCTURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if os.path.exists(rip_dataset_path):\n",
    "    print(\"\\n🌊 Rip Current Dataset:\")\n",
    "    print(\"rip/\")\n",
    "    display_folder_tree(rip_dataset_path)\n",
    "\n",
    "if os.path.exists(beach_dataset_path):\n",
    "    print(\"\\n🏖️ Beach Classification Dataset:\")\n",
    "    print(\"beach/\")\n",
    "    display_folder_tree(beach_dataset_path)\n",
    "\n",
    "print(f\"\\n✅ DATASET VERIFICATION COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab80588",
   "metadata": {},
   "source": [
    "### Dataset Analysis and Statistics\n",
    "\n",
    "Let's analyze both datasets to understand their structure and combine the rip current datasets for better training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Analysis for Paperspace Environment\n",
    "print(\"📊 DATASET ANALYSIS - PAPERSPACE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze mounted datasets\n",
    "def analyze_dataset_structure(path, dataset_name):\n",
    "    \"\"\"Analyze the structure of a mounted dataset\"\"\"\n",
    "    stats = defaultdict(lambda: defaultdict(int))\n",
    "    total_images = 0\n",
    "    \n",
    "    print(f\"\\n🔍 Analyzing {dataset_name}: {path}\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"❌ Dataset not found at {path}\")\n",
    "        return stats, 0\n",
    "    \n",
    "    # Walk through directory structure\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        images = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "        labels = [f for f in files if f.endswith('.txt')]\n",
    "        \n",
    "        if images:\n",
    "            rel_path = os.path.relpath(root, path)\n",
    "            level = rel_path.count(os.sep)\n",
    "            indent = '  ' * level\n",
    "            folder_name = os.path.basename(root)\n",
    "            \n",
    "            print(f\"{indent}📁 {folder_name}: {len(images)} images, {len(labels)} labels\")\n",
    "            \n",
    "            # Track statistics\n",
    "            if 'train' in rel_path.lower():\n",
    "                stats['train']['images'] += len(images)\n",
    "                stats['train']['labels'] += len(labels)\n",
    "            elif 'test' in rel_path.lower():\n",
    "                stats['test']['images'] += len(images)\n",
    "                stats['test']['labels'] += len(labels)\n",
    "            elif 'val' in rel_path.lower() or 'valid' in rel_path.lower():\n",
    "                stats['valid']['images'] += len(images)\n",
    "                stats['valid']['labels'] += len(labels)\n",
    "            else:\n",
    "                stats['other']['images'] += len(images)\n",
    "                stats['other']['labels'] += len(labels)\n",
    "            \n",
    "            total_images += len(images)\n",
    "    \n",
    "    return stats, total_images\n",
    "\n",
    "# Analyze both datasets\n",
    "rip_stats, total_rip_images = analyze_dataset_structure(rip_dataset_path, \"Rip Current Dataset\")\n",
    "beach_stats, total_beach_images = analyze_dataset_structure(beach_dataset_path, \"Beach Classification Dataset\")\n",
    "\n",
    "print(f\"\\n📊 DATASET SUMMARIES:\")\n",
    "print(f\"🌊 Rip Current Dataset: {total_rip_images} total images\")\n",
    "for split, counts in rip_stats.items():\n",
    "    if counts['images'] > 0:\n",
    "        print(f\"   {split}: {counts['images']} images, {counts['labels']} labels\")\n",
    "\n",
    "print(f\"🏖️ Beach Classification Dataset: {total_beach_images} total images\")\n",
    "for split, counts in beach_stats.items():\n",
    "    if counts['images'] > 0:\n",
    "        print(f\"   {split}: {counts['images']} images, {counts['labels']} labels\")\n",
    "\n",
    "# Create combined dataset in working directory\n",
    "print(f\"\\n🔄 CREATING COMBINED DATASETS...\")\n",
    "combined_rip_path = f'{working_dir}/combined_rip_dataset'\n",
    "combined_beach_path = f'{working_dir}/beach_classification_dataset'\n",
    "\n",
    "# Create directory structures\n",
    "for dataset_path in [combined_rip_path, combined_beach_path]:\n",
    "    for split in ['train', 'test', 'valid']:\n",
    "        os.makedirs(f'{dataset_path}/{split}/images', exist_ok=True)\n",
    "        os.makedirs(f'{dataset_path}/{split}/labels', exist_ok=True)\n",
    "\n",
    "print(f\"✅ Directory structures created\")\n",
    "print(f\"📍 Combined rip dataset: {combined_rip_path}\")\n",
    "print(f\"📍 Combined beach dataset: {combined_beach_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and organize datasets for training\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"📋 ORGANIZING DATASETS FOR TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def copy_dataset_files(source_path, dest_path, dataset_name):\n",
    "    \"\"\"Copy and organize dataset files\"\"\"\n",
    "    copy_stats = defaultdict(int)\n",
    "    \n",
    "    print(f\"\\n📂 Processing {dataset_name}...\")\n",
    "    \n",
    "    if not os.path.exists(source_path):\n",
    "        print(f\"❌ Source path not found: {source_path}\")\n",
    "        return copy_stats\n",
    "    \n",
    "    # Walk through source directory\n",
    "    for root, dirs, files in os.walk(source_path):\n",
    "        images = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "        labels = [f for f in files if f.endswith('.txt') and f != 'classes.txt']\n",
    "        \n",
    "        if images:\n",
    "            # Determine split based on path\n",
    "            rel_path = os.path.relpath(root, source_path)\n",
    "            \n",
    "            if 'train' in rel_path.lower():\n",
    "                split = 'train'\n",
    "            elif 'test' in rel_path.lower():\n",
    "                split = 'test'\n",
    "            elif 'val' in rel_path.lower() or 'valid' in rel_path.lower():\n",
    "                split = 'valid'\n",
    "            else:\n",
    "                split = 'train'  # Default to train if unclear\n",
    "            \n",
    "            dest_images_dir = f'{dest_path}/{split}/images'\n",
    "            dest_labels_dir = f'{dest_path}/{split}/labels'\n",
    "            \n",
    "            # Copy images\n",
    "            for img_file in images:\n",
    "                src = os.path.join(root, img_file)\n",
    "                dst = os.path.join(dest_images_dir, img_file)\n",
    "                \n",
    "                # Avoid duplicates\n",
    "                if not os.path.exists(dst):\n",
    "                    shutil.copy2(src, dst)\n",
    "                    copy_stats[f'{split}_images'] += 1\n",
    "            \n",
    "            # Copy corresponding labels\n",
    "            for label_file in labels:\n",
    "                src = os.path.join(root, label_file)\n",
    "                dst = os.path.join(dest_labels_dir, label_file)\n",
    "                \n",
    "                if not os.path.exists(dst):\n",
    "                    shutil.copy2(src, dst)\n",
    "                    copy_stats[f'{split}_labels'] += 1\n",
    "    \n",
    "    return copy_stats\n",
    "\n",
    "# Copy rip current dataset\n",
    "rip_copy_stats = copy_dataset_files(rip_dataset_path, combined_rip_path, \"Rip Current Dataset\")\n",
    "\n",
    "# Copy beach classification dataset\n",
    "beach_copy_stats = copy_dataset_files(beach_dataset_path, combined_beach_path, \"Beach Classification Dataset\")\n",
    "\n",
    "# Create YAML configuration files\n",
    "print(f\"\\n📝 CREATING CONFIGURATION FILES...\")\n",
    "\n",
    "# Create rip dataset YAML\n",
    "rip_yaml_content = {\n",
    "    'train': f'{combined_rip_path}/train/images',\n",
    "    'val': f'{combined_rip_path}/valid/images',\n",
    "    'test': f'{combined_rip_path}/test/images',\n",
    "    'nc': 1,\n",
    "    'names': ['rip_current']\n",
    "}\n",
    "\n",
    "with open(f'{combined_rip_path}/data.yaml', 'w') as f:\n",
    "    yaml.dump(rip_yaml_content, f)\n",
    "\n",
    "# Create beach dataset YAML (for classification)\n",
    "beach_yaml_content = {\n",
    "    'train': f'{combined_beach_path}/train',\n",
    "    'val': f'{combined_beach_path}/valid',\n",
    "    'test': f'{combined_beach_path}/test',\n",
    "    'nc': 2,\n",
    "    'names': ['beach', 'not_beach']\n",
    "}\n",
    "\n",
    "with open(f'{combined_beach_path}/data.yaml', 'w') as f:\n",
    "    yaml.dump(beach_yaml_content, f)\n",
    "\n",
    "print(f\"✅ Configuration files created\")\n",
    "\n",
    "# Display final statistics\n",
    "print(f\"\\n📊 FINAL DATASET STATISTICS:\")\n",
    "print(f\"🌊 Rip Current Dataset:\")\n",
    "total_rip = 0\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    img_count = rip_copy_stats[f'{split}_images']\n",
    "    label_count = rip_copy_stats[f'{split}_labels']\n",
    "    total_rip += img_count\n",
    "    print(f\"   {split:>5}: {img_count:>4} images, {label_count:>4} labels\")\n",
    "print(f\"   Total: {total_rip} images\")\n",
    "\n",
    "print(f\"\\n🏖️ Beach Classification Dataset:\")\n",
    "total_beach = 0\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    img_count = beach_copy_stats[f'{split}_images']\n",
    "    total_beach += img_count\n",
    "    print(f\"   {split:>5}: {img_count:>4} images\")\n",
    "print(f\"   Total: {total_beach} images\")\n",
    "\n",
    "print(f\"\\n🎯 DATASETS READY FOR TRAINING!\")\n",
    "print(f\"📍 Rip detection dataset: {combined_rip_path}\")\n",
    "print(f\"📍 Beach classification dataset: {combined_beach_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7728e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Paperspace\n",
    "print(\"📦 INSTALLING REQUIRED PACKAGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package, upgrade=False):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\"]\n",
    "        if upgrade:\n",
    "            cmd.append(\"--upgrade\")\n",
    "        cmd.extend([package, \"-q\"])\n",
    "        \n",
    "        subprocess.check_call(cmd)\n",
    "        print(f\"✅ {package} installed successfully\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Install essential packages\n",
    "packages = [\n",
    "    \"ultralytics\",\n",
    "    \"opencv-python\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"pillow\",\n",
    "    \"pyyaml\"\n",
    "]\n",
    "\n",
    "print(\"Installing packages...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "# Import and verify installations\n",
    "print(f\"\\n🔍 VERIFYING INSTALLATIONS:\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✅ PyTorch {torch.__version__}\")\n",
    "    print(f\"✅ CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"✅ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        print(f\"⚠️ Running on CPU\")\n",
    "except ImportError:\n",
    "    print(f\"❌ PyTorch not available\")\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print(f\"✅ Ultralytics YOLO imported successfully\")\n",
    "except ImportError:\n",
    "    print(f\"❌ Ultralytics not available\")\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"✅ OpenCV {cv2.__version__}\")\n",
    "except ImportError:\n",
    "    print(f\"❌ OpenCV not available\")\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    print(f\"✅ Matplotlib {matplotlib.__version__}\")\n",
    "except ImportError:\n",
    "    print(f\"❌ Matplotlib not available\")\n",
    "\n",
    "print(f\"\\n🚀 ENVIRONMENT READY FOR TRAINING!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45328f62",
   "metadata": {},
   "source": [
    "## 2. Model Training - Stage 1: Beach Classification\n",
    "\n",
    "Train a YOLOv8 classification model to distinguish between beach and non-beach images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Train Beach Classifier for Paperspace\n",
    "print(\"🏖️ STAGE 1: TRAINING BEACH CLASSIFIER - PAPERSPACE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Training configuration for Paperspace\n",
    "BEACH_EPOCHS = 50\n",
    "BEACH_BATCH_SIZE = 16\n",
    "BEACH_IMAGE_SIZE = 224\n",
    "PATIENCE = 10\n",
    "\n",
    "# Model save paths in persistent storage\n",
    "beach_model_dir = f'{working_dir}/models/beach_classifier'\n",
    "os.makedirs(beach_model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\n⚙️ TRAINING CONFIGURATION:\")\n",
    "print(f\"   Epochs: {BEACH_EPOCHS}\")\n",
    "print(f\"   Batch size: {BEACH_BATCH_SIZE}\")\n",
    "print(f\"   Image size: {BEACH_IMAGE_SIZE}\")\n",
    "print(f\"   Patience: {PATIENCE}\")\n",
    "print(f\"   Model save dir: {beach_model_dir}\")\n",
    "print(f\"   Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Initialize model\n",
    "print(f\"\\n🤖 INITIALIZING BEACH CLASSIFIER...\")\n",
    "beach_model = YOLO('yolov8n-cls.pt')\n",
    "print(f\"✅ YOLOv8n-cls model loaded\")\n",
    "\n",
    "# Verify dataset structure\n",
    "print(f\"\\n🔍 VERIFYING BEACH DATASET:\")\n",
    "train_path = f'{combined_beach_path}/train'\n",
    "if os.path.exists(train_path):\n",
    "    subdirs = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
    "    print(f\"   Training classes: {subdirs}\")\n",
    "    for subdir in subdirs:\n",
    "        count = len([f for f in os.listdir(os.path.join(train_path, subdir)) \n",
    "                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"   {subdir}: {count} images\")\n",
    "else:\n",
    "    print(f\"❌ Training path not found: {train_path}\")\n",
    "\n",
    "# Start training\n",
    "print(f\"\\n🚀 STARTING BEACH CLASSIFIER TRAINING...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    results = beach_model.train(\n",
    "        data=train_path,\n",
    "        epochs=BEACH_EPOCHS,\n",
    "        imgsz=BEACH_IMAGE_SIZE,\n",
    "        batch=BEACH_BATCH_SIZE,\n",
    "        patience=PATIENCE,\n",
    "        save=True,\n",
    "        plots=True,\n",
    "        project=beach_model_dir,\n",
    "        name='beach_classification',\n",
    "        device='0' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n✅ BEACH CLASSIFIER TRAINING COMPLETED!\")\n",
    "    print(f\"⏱️ Training time: {training_time/60:.1f} minutes\")\n",
    "    \n",
    "    # Save best model to easy access location\n",
    "    best_model_path = f'{working_dir}/beach_classifier_best.pt'\n",
    "    trained_path = f'{beach_model_dir}/beach_classification/weights/best.pt'\n",
    "    \n",
    "    if os.path.exists(trained_path):\n",
    "        import shutil\n",
    "        shutil.copy2(trained_path, best_model_path)\n",
    "        print(f\"💾 Best model saved to: {best_model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {str(e)}\")\n",
    "    print(f\"💡 Check dataset format and available memory\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"🏖️ STAGE 1 COMPLETED\")\n",
    "print(f\"📍 Model location: {beach_model_dir}/beach_classification/weights/best.pt\")\n",
    "print(f\"🚀 Ready for Stage 2: Rip Current Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa0b82",
   "metadata": {},
   "source": [
    "## 3. Model Training - Stage 2: Rip Current Detection\n",
    "\n",
    "Train a YOLOv8 object detection model to detect rip currents in beach images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d88feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Train Rip Current Detector for Paperspace\n",
    "print(\"🌊 STAGE 2: TRAINING RIP CURRENT DETECTOR - PAPERSPACE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Training configuration for Paperspace\n",
    "RIP_EPOCHS = 100\n",
    "RIP_BATCH_SIZE = 16\n",
    "RIP_IMAGE_SIZE = 640\n",
    "RIP_PATIENCE = 15\n",
    "\n",
    "# Model save paths in persistent storage\n",
    "rip_model_dir = f'{working_dir}/models/rip_detector'\n",
    "os.makedirs(rip_model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\n⚙️ TRAINING CONFIGURATION:\")\n",
    "print(f\"   Epochs: {RIP_EPOCHS}\")\n",
    "print(f\"   Batch size: {RIP_BATCH_SIZE}\")\n",
    "print(f\"   Image size: {RIP_IMAGE_SIZE}\")\n",
    "print(f\"   Patience: {RIP_PATIENCE}\")\n",
    "print(f\"   Model save dir: {rip_model_dir}\")\n",
    "print(f\"   Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Initialize model\n",
    "print(f\"\\n🤖 INITIALIZING RIP DETECTOR...\")\n",
    "rip_model = YOLO('yolov8n.pt')\n",
    "print(f\"✅ YOLOv8n model loaded\")\n",
    "\n",
    "# Verify dataset and YAML\n",
    "yaml_path = f'{combined_rip_path}/data.yaml'\n",
    "print(f\"\\n🔍 VERIFYING RIP DATASET:\")\n",
    "print(f\"   YAML config: {yaml_path}\")\n",
    "\n",
    "if os.path.exists(yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        yaml_content = yaml.safe_load(f)\n",
    "        print(f\"   Classes: {yaml_content.get('names', 'Unknown')}\")\n",
    "        print(f\"   Number of classes: {yaml_content.get('nc', 'Unknown')}\")\n",
    "\n",
    "# Check training data\n",
    "train_images_path = f'{combined_rip_path}/train/images'\n",
    "train_labels_path = f'{combined_rip_path}/train/labels'\n",
    "\n",
    "if os.path.exists(train_images_path):\n",
    "    img_count = len([f for f in os.listdir(train_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    label_count = len([f for f in os.listdir(train_labels_path) if f.endswith('.txt')]) if os.path.exists(train_labels_path) else 0\n",
    "    print(f\"   Training: {img_count} images, {label_count} labels\")\n",
    "else:\n",
    "    print(f\"❌ Training images not found: {train_images_path}\")\n",
    "\n",
    "# Start training\n",
    "print(f\"\\n🚀 STARTING RIP DETECTOR TRAINING...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    results = rip_model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=RIP_EPOCHS,\n",
    "        imgsz=RIP_IMAGE_SIZE,\n",
    "        batch=RIP_BATCH_SIZE,\n",
    "        patience=RIP_PATIENCE,\n",
    "        save=True,\n",
    "        plots=True,\n",
    "        project=rip_model_dir,\n",
    "        name='rip_detection',\n",
    "        device='0' if torch.cuda.is_available() else 'cpu',\n",
    "        workers=2\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n✅ RIP DETECTOR TRAINING COMPLETED!\")\n",
    "    print(f\"⏱️ Training time: {training_time/60:.1f} minutes\")\n",
    "    \n",
    "    # Save best model to easy access location\n",
    "    best_model_path = f'{working_dir}/rip_detector_best.pt'\n",
    "    trained_path = f'{rip_model_dir}/rip_detection/weights/best.pt'\n",
    "    \n",
    "    if os.path.exists(trained_path):\n",
    "        import shutil\n",
    "        shutil.copy2(trained_path, best_model_path)\n",
    "        print(f\"💾 Best model saved to: {best_model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {str(e)}\")\n",
    "    print(f\"💡 Check dataset format, YAML config, and available memory\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"🌊 STAGE 2 COMPLETED\")\n",
    "print(f\"📍 Model location: {rip_model_dir}/rip_detection/weights/best.pt\")\n",
    "print(f\"🚀 Ready for Stage 3: Two-Stage Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c57f6a",
   "metadata": {},
   "source": [
    "## 4. Two-Stage Inference Pipeline\n",
    "\n",
    "Create and test the complete two-stage inference pipeline for Paperspace environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60345ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-Stage Pipeline for Paperspace\n",
    "print(\"🔗 CREATING TWO-STAGE INFERENCE PIPELINE - PAPERSPACE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define model paths in Paperspace storage\n",
    "BEACH_MODEL_PATH = f'{working_dir}/beach_classifier_best.pt'\n",
    "RIP_MODEL_PATH = f'{working_dir}/rip_detector_best.pt'\n",
    "\n",
    "# Alternative paths from training directories\n",
    "ALT_BEACH_PATH = f'{working_dir}/models/beach_classifier/beach_classification/weights/best.pt'\n",
    "ALT_RIP_PATH = f'{working_dir}/models/rip_detector/rip_detection/weights/best.pt'\n",
    "\n",
    "print(f\"\\n🔍 CHECKING FOR TRAINED MODELS:\")\n",
    "\n",
    "# Check for beach classifier\n",
    "beach_model_found = False\n",
    "if os.path.exists(BEACH_MODEL_PATH):\n",
    "    print(f\"✅ Beach classifier found: {BEACH_MODEL_PATH}\")\n",
    "    beach_model_found = True\n",
    "elif os.path.exists(ALT_BEACH_PATH):\n",
    "    print(f\"✅ Beach classifier found: {ALT_BEACH_PATH}\")\n",
    "    BEACH_MODEL_PATH = ALT_BEACH_PATH\n",
    "    beach_model_found = True\n",
    "else:\n",
    "    print(f\"⚠️ Beach classifier not found - will use pretrained for demo\")\n",
    "    BEACH_MODEL_PATH = 'yolov8n-cls.pt'\n",
    "\n",
    "# Check for rip detector\n",
    "rip_model_found = False\n",
    "if os.path.exists(RIP_MODEL_PATH):\n",
    "    print(f\"✅ Rip detector found: {RIP_MODEL_PATH}\")\n",
    "    rip_model_found = True\n",
    "elif os.path.exists(ALT_RIP_PATH):\n",
    "    print(f\"✅ Rip detector found: {ALT_RIP_PATH}\")\n",
    "    RIP_MODEL_PATH = ALT_RIP_PATH\n",
    "    rip_model_found = True\n",
    "else:\n",
    "    print(f\"⚠️ Rip detector not found - will use pretrained for demo\")\n",
    "    RIP_MODEL_PATH = 'yolov8n.pt'\n",
    "\n",
    "# Load models\n",
    "print(f\"\\n🤖 LOADING MODELS...\")\n",
    "try:\n",
    "    beach_classifier = YOLO(BEACH_MODEL_PATH)\n",
    "    print(f\"✅ Beach classifier loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load beach classifier: {e}\")\n",
    "    beach_classifier = None\n",
    "\n",
    "try:\n",
    "    rip_detector = YOLO(RIP_MODEL_PATH)\n",
    "    print(f\"✅ Rip detector loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load rip detector: {e}\")\n",
    "    rip_detector = None\n",
    "\n",
    "# Define the Two-Stage Pipeline Class for Paperspace\n",
    "class PaperspaceRipCurrentPipeline:\n",
    "    def __init__(self, beach_classifier, rip_detector, beach_threshold=0.7, rip_threshold=0.5):\n",
    "        self.beach_classifier = beach_classifier\n",
    "        self.rip_detector = rip_detector\n",
    "        self.beach_threshold = beach_threshold\n",
    "        self.rip_threshold = rip_threshold\n",
    "        \n",
    "        # Create results directory\n",
    "        self.results_dir = f'{working_dir}/pipeline_results'\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "    \n",
    "    def predict(self, image_path, verbose=True, save_results=True):\n",
    "        \"\"\"Two-stage prediction pipeline optimized for Paperspace\"\"\"\n",
    "        results = {\n",
    "            'image_path': image_path,\n",
    "            'is_beach': False,\n",
    "            'beach_confidence': 0.0,\n",
    "            'rip_detections': [],\n",
    "            'total_rips': 0,\n",
    "            'processing_time': 0.0,\n",
    "            'message': '',\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            if verbose:\n",
    "                print(f\"\\n🖼️ Processing: {os.path.basename(image_path)}\")\n",
    "                print(f\"🏖️ Stage 1: Beach classification...\")\n",
    "            \n",
    "            # Stage 1: Beach Classification\n",
    "            if self.beach_classifier is not None:\n",
    "                beach_results = self.beach_classifier(image_path, verbose=False)\n",
    "                \n",
    "                if hasattr(beach_results[0], 'probs'):\n",
    "                    beach_confidence = float(beach_results[0].probs.top1conf)\n",
    "                    top_class = int(beach_results[0].probs.top1)\n",
    "                    \n",
    "                    # Determine if it's a beach\n",
    "                    is_beach = (top_class == 0 and beach_confidence > self.beach_threshold)\n",
    "                    \n",
    "                    results['beach_confidence'] = beach_confidence\n",
    "                    results['is_beach'] = is_beach\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"   Beach confidence: {beach_confidence:.3f}\")\n",
    "                        print(f\"   Is beach: {is_beach}\")\n",
    "                else:\n",
    "                    # Fallback\n",
    "                    results['is_beach'] = True\n",
    "                    results['beach_confidence'] = 0.8\n",
    "                    if verbose:\n",
    "                        print(f\"   Using fallback beach detection\")\n",
    "            else:\n",
    "                results['is_beach'] = True\n",
    "                results['beach_confidence'] = 1.0\n",
    "                if verbose:\n",
    "                    print(f\"   No beach classifier - assuming beach\")\n",
    "            \n",
    "            # Stage 2: Rip Current Detection\n",
    "            if results['is_beach']:\n",
    "                if verbose:\n",
    "                    print(f\"🌊 Stage 2: Rip current detection...\")\n",
    "                \n",
    "                if self.rip_detector is not None:\n",
    "                    rip_results = self.rip_detector(image_path, verbose=False)\n",
    "                    \n",
    "                    detections = []\n",
    "                    for result in rip_results:\n",
    "                        if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                            boxes = result.boxes\n",
    "                            for i in range(len(boxes.xyxy)):\n",
    "                                confidence = float(boxes.conf[i])\n",
    "                                if confidence > self.rip_threshold:\n",
    "                                    bbox = boxes.xyxy[i].cpu().numpy()\n",
    "                                    detections.append({\n",
    "                                        'bbox': bbox.tolist(),\n",
    "                                        'confidence': confidence,\n",
    "                                        'class': 'rip_current'\n",
    "                                    })\n",
    "                    \n",
    "                    results['rip_detections'] = detections\n",
    "                    results['total_rips'] = len(detections)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"   Rip currents detected: {len(detections)}\")\n",
    "                        for i, det in enumerate(detections):\n",
    "                            print(f\"   Detection {i+1}: confidence {det['confidence']:.3f}\")\n",
    "                \n",
    "                results['message'] = f\"Beach detected! Found {results['total_rips']} rip current(s)\"\n",
    "            else:\n",
    "                results['message'] = \"Not a beach image - no rip detection performed\"\n",
    "                if verbose:\n",
    "                    print(f\"❌ Not a beach - skipping rip detection\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['message'] = f\"Error during processing: {str(e)}\"\n",
    "            if verbose:\n",
    "                print(f\"❌ Error: {str(e)}\")\n",
    "        \n",
    "        results['processing_time'] = time.time() - start_time\n",
    "        \n",
    "        # Save results if requested\n",
    "        if save_results:\n",
    "            self.save_results(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results(self, results):\n",
    "        \"\"\"Save prediction results to storage\"\"\"\n",
    "        import json\n",
    "        timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'prediction_{timestamp}.json'\n",
    "        filepath = os.path.join(self.results_dir, filename)\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    \n",
    "    def visualize_results(self, image_path, results, save_viz=True):\n",
    "        \"\"\"Visualize detection results\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(image_rgb)\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            if results['rip_detections']:\n",
    "                for detection in results['rip_detections']:\n",
    "                    bbox = detection['bbox']\n",
    "                    confidence = detection['confidence']\n",
    "                    \n",
    "                    rect = plt.Rectangle(\n",
    "                        (bbox[0], bbox[1]), \n",
    "                        bbox[2] - bbox[0], \n",
    "                        bbox[3] - bbox[1],\n",
    "                        linewidth=3, \n",
    "                        edgecolor='red', \n",
    "                        facecolor='none'\n",
    "                    )\n",
    "                    plt.gca().add_patch(rect)\n",
    "                    \n",
    "                    plt.text(\n",
    "                        bbox[0], bbox[1] - 10, \n",
    "                        f'Rip: {confidence:.2f}', \n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='red', alpha=0.7),\n",
    "                        fontsize=10, color='white'\n",
    "                    )\n",
    "            \n",
    "            title = f\"Beach: {results['beach_confidence']:.2f} | Rips: {results['total_rips']} | {results['message']}\"\n",
    "            plt.title(title, fontsize=12, pad=20)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_viz:\n",
    "                timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "                viz_filename = f'visualization_{timestamp}.png'\n",
    "                viz_path = os.path.join(self.results_dir, viz_filename)\n",
    "                plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
    "                print(f\"📸 Visualization saved: {viz_path}\")\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Visualization error: {str(e)}\")\n",
    "\n",
    "# Initialize the pipeline\n",
    "print(f\"\\n🔗 INITIALIZING PAPERSPACE PIPELINE...\")\n",
    "pipeline = PaperspaceRipCurrentPipeline(\n",
    "    beach_classifier=beach_classifier,\n",
    "    rip_detector=rip_detector,\n",
    "    beach_threshold=0.7,\n",
    "    rip_threshold=0.5\n",
    ")\n",
    "\n",
    "print(f\"✅ Pipeline initialized!\")\n",
    "print(f\"📍 Results will be saved to: {pipeline.results_dir}\")\n",
    "print(f\"🎯 Pipeline ready for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7da74",
   "metadata": {},
   "source": [
    "## 4. Summary and Next Steps\n",
    "\n",
    "### Project Achievements\n",
    "\n",
    "✅ **Two-Stage Pipeline Implemented**: Successfully created a comprehensive rip current detection system that first classifies beach vs non-beach images, then detects rip currents in confirmed beach images.\n",
    "\n",
    "✅ **Dataset Integration**: Combined multiple rip current datasets for better training coverage and analyzed beach classification dataset for effective filtering.\n",
    "\n",
    "✅ **Model Training**: Trained both YOLOv8 classification (beach detection) and YOLOv8 object detection (rip current detection) models.\n",
    "\n",
    "✅ **Complete Pipeline**: Created an end-to-end inference system with visualization capabilities.\n",
    "\n",
    "### Key Benefits of Two-Stage Approach\n",
    "\n",
    "1. **Reduced False Positives**: By filtering out non-beach images first, we eliminate false rip current detections in irrelevant images.\n",
    "\n",
    "2. **Improved Accuracy**: The rip detector can focus specifically on beach images, improving its performance.\n",
    "\n",
    "3. **Computational Efficiency**: Skip expensive rip detection on non-beach images.\n",
    "\n",
    "4. **Modular Design**: Each stage can be improved independently.\n",
    "\n",
    "### Next Steps for Production\n",
    "\n",
    "1. **Model Optimization**:\n",
    "   - Experiment with larger YOLOv8 models (s, m, l, x) for better accuracy\n",
    "   - Fine-tune hyperparameters based on validation results\n",
    "   - Implement data augmentation strategies\n",
    "\n",
    "2. **Dataset Enhancement**:\n",
    "   - Collect more diverse beach and rip current images\n",
    "   - Include challenging conditions (different lighting, weather)\n",
    "   - Add geographical diversity\n",
    "\n",
    "3. **Performance Improvements**:\n",
    "   - Implement model quantization for faster inference\n",
    "   - Add multi-scale testing\n",
    "   - Consider ensemble methods\n",
    "\n",
    "4. **Production Deployment**:\n",
    "   - Create REST API for the pipeline\n",
    "   - Add batch processing capabilities\n",
    "   - Implement proper error handling and logging\n",
    "   - Add model versioning and A/B testing\n",
    "\n",
    "### Usage Examples\n",
    "\n",
    "```python\n",
    "# Initialize pipeline\n",
    "pipeline = RipCurrentPipeline(beach_classifier, rip_detector)\n",
    "\n",
    "# Process single image\n",
    "results = pipeline.predict('path/to/beach_image.jpg')\n",
    "print(f\"Beach confidence: {results['beach_confidence']:.3f}\")\n",
    "print(f\"Rip currents found: {results['total_rips']}\")\n",
    "\n",
    "# Visualize results\n",
    "pipeline.visualize_results('path/to/beach_image.jpg', results)\n",
    "```\n",
    "\n",
    "This notebook provides a complete foundation for rip current detection with significant potential for real-world safety applications."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
